{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changelog\n",
    "* V1.0 \n",
    "    - Adding masking layer\n",
    "* V1.1\n",
    "    - Scaling dataset using RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iss/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from pandas import DataFrame, Series\n",
    "from keras.layers import Dense, LSTM, SimpleRNN, Masking\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = DataFrame.from_csv(\"./testosterone_levels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tail_length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding seq_ix to data\n",
    "seq_ix = [list(np.arange(i)) for i in data.groupby(\"Person\").size().values]\n",
    "seq_ix = [item for sub in seq_ix for item in sub]\n",
    "data.index = pd.MultiIndex.from_arrays([data.index.values, seq_ix], names=['Person', 'seq_ix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.fillna(method='pad', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scaling data\n",
    "scaler = RobustScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "scaled_data = DataFrame(scaled_data, index = data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dividing dataset for creating labels (train-test validation)\n",
    "person_heads = []\n",
    "person_tails = []\n",
    "for id, details in scaled_data.groupby(\"Person\"):\n",
    "    head = details.head(len(details) - tail_length).values\n",
    "    tail = details.tail(tail_length).values\n",
    "    person_heads.append(head)\n",
    "    person_tails.append(tail)\n",
    "person_tails = np.array(person_tails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# padding data\n",
    "person_heads = sequence.pad_sequences(np.array(person_heads), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# spliting train/test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(person_heads, person_tails, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_1 (Masking)          (None, 17, 5)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 17, 100)           42400     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 122,901\n",
      "Trainable params: 122,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# creating model\n",
    "model = Sequential()\n",
    "model.add(Masking(input_shape=(x_train.shape[1], x_train.shape[2])))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1))\n",
    "from keras.optimizers import adam\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defining callbacks\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "tensorboard_callback = TensorBoard(log_dir=\"./logs/2_LSTM_100_run26_maskingLayer_scaled_batch2\" , histogram_freq=1, batch_size=1)\n",
    "earlystopping_callback = EarlyStopping(min_delta=.001 , patience=20, mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 110 samples, validate on 28 samples\n",
      "Epoch 1/100\n",
      "110/110 [==============================] - 2s - loss: 2.2089 - mean_absolute_error: 0.7443 - val_loss: 0.5701 - val_mean_absolute_error: 0.4539\n",
      "Epoch 2/100\n",
      "110/110 [==============================] - 2s - loss: 0.8647 - mean_absolute_error: 0.4431 - val_loss: 0.3501 - val_mean_absolute_error: 0.3111\n",
      "Epoch 3/100\n",
      "110/110 [==============================] - 2s - loss: 1.0468 - mean_absolute_error: 0.6047 - val_loss: 0.7071 - val_mean_absolute_error: 0.5048\n",
      "Epoch 4/100\n",
      "110/110 [==============================] - 2s - loss: 0.7384 - mean_absolute_error: 0.4331 - val_loss: 0.3355 - val_mean_absolute_error: 0.3618\n",
      "Epoch 5/100\n",
      "110/110 [==============================] - 2s - loss: 0.4948 - mean_absolute_error: 0.4001 - val_loss: 0.2914 - val_mean_absolute_error: 0.3308\n",
      "Epoch 6/100\n",
      "110/110 [==============================] - 2s - loss: 0.2620 - mean_absolute_error: 0.2874 - val_loss: 0.2501 - val_mean_absolute_error: 0.3033\n",
      "Epoch 7/100\n",
      "110/110 [==============================] - 2s - loss: 0.1992 - mean_absolute_error: 0.3173 - val_loss: 0.2797 - val_mean_absolute_error: 0.3066\n",
      "Epoch 8/100\n",
      "110/110 [==============================] - 2s - loss: 0.1498 - mean_absolute_error: 0.2371 - val_loss: 0.1771 - val_mean_absolute_error: 0.2471\n",
      "Epoch 9/100\n",
      "110/110 [==============================] - 2s - loss: 0.0832 - mean_absolute_error: 0.2003 - val_loss: 0.1938 - val_mean_absolute_error: 0.2698\n",
      "Epoch 10/100\n",
      "110/110 [==============================] - 2s - loss: 0.0922 - mean_absolute_error: 0.2170 - val_loss: 0.1282 - val_mean_absolute_error: 0.2201\n",
      "Epoch 11/100\n",
      "110/110 [==============================] - 2s - loss: 0.1925 - mean_absolute_error: 0.2603 - val_loss: 0.2380 - val_mean_absolute_error: 0.2872\n",
      "Epoch 12/100\n",
      "110/110 [==============================] - 2s - loss: 0.2098 - mean_absolute_error: 0.2940 - val_loss: 0.1843 - val_mean_absolute_error: 0.2572\n",
      "Epoch 13/100\n",
      "110/110 [==============================] - 2s - loss: 0.2035 - mean_absolute_error: 0.2589 - val_loss: 0.1737 - val_mean_absolute_error: 0.2398\n",
      "Epoch 14/100\n",
      "110/110 [==============================] - 2s - loss: 0.2799 - mean_absolute_error: 0.2846 - val_loss: 0.1509 - val_mean_absolute_error: 0.2212\n",
      "Epoch 15/100\n",
      "110/110 [==============================] - 2s - loss: 0.0641 - mean_absolute_error: 0.1776 - val_loss: 0.1324 - val_mean_absolute_error: 0.2238\n",
      "Epoch 16/100\n",
      "110/110 [==============================] - 2s - loss: 0.0607 - mean_absolute_error: 0.1747 - val_loss: 0.1366 - val_mean_absolute_error: 0.2188\n",
      "Epoch 17/100\n",
      "110/110 [==============================] - 2s - loss: 0.0627 - mean_absolute_error: 0.1762 - val_loss: 0.1346 - val_mean_absolute_error: 0.2271\n",
      "Epoch 18/100\n",
      "110/110 [==============================] - 2s - loss: 0.0611 - mean_absolute_error: 0.1713 - val_loss: 0.1187 - val_mean_absolute_error: 0.2028\n",
      "Epoch 19/100\n",
      "110/110 [==============================] - 2s - loss: 0.0544 - mean_absolute_error: 0.1611 - val_loss: 0.1157 - val_mean_absolute_error: 0.2011\n",
      "Epoch 20/100\n",
      "110/110 [==============================] - 2s - loss: 0.0486 - mean_absolute_error: 0.1544 - val_loss: 0.1160 - val_mean_absolute_error: 0.2262\n",
      "Epoch 21/100\n",
      "110/110 [==============================] - 2s - loss: 0.0566 - mean_absolute_error: 0.1692 - val_loss: 0.1091 - val_mean_absolute_error: 0.1910\n",
      "Epoch 22/100\n",
      "110/110 [==============================] - 2s - loss: 0.0445 - mean_absolute_error: 0.1519 - val_loss: 0.1135 - val_mean_absolute_error: 0.2009\n",
      "Epoch 23/100\n",
      "110/110 [==============================] - 2s - loss: 0.0503 - mean_absolute_error: 0.1596 - val_loss: 0.1033 - val_mean_absolute_error: 0.1947\n",
      "Epoch 24/100\n",
      "110/110 [==============================] - 2s - loss: 0.0506 - mean_absolute_error: 0.1511 - val_loss: 0.1071 - val_mean_absolute_error: 0.1984\n",
      "Epoch 25/100\n",
      "110/110 [==============================] - 2s - loss: 0.0382 - mean_absolute_error: 0.1332 - val_loss: 0.1070 - val_mean_absolute_error: 0.1862\n",
      "Epoch 26/100\n",
      "110/110 [==============================] - 2s - loss: 0.0466 - mean_absolute_error: 0.1523 - val_loss: 0.1030 - val_mean_absolute_error: 0.1936\n",
      "Epoch 27/100\n",
      "110/110 [==============================] - 2s - loss: 0.0424 - mean_absolute_error: 0.1486 - val_loss: 0.1064 - val_mean_absolute_error: 0.1919\n",
      "Epoch 28/100\n",
      "110/110 [==============================] - 2s - loss: 0.0410 - mean_absolute_error: 0.1520 - val_loss: 0.1035 - val_mean_absolute_error: 0.1906\n",
      "Epoch 29/100\n",
      "110/110 [==============================] - 2s - loss: 0.0394 - mean_absolute_error: 0.1406 - val_loss: 0.1085 - val_mean_absolute_error: 0.2062\n",
      "Epoch 30/100\n",
      "110/110 [==============================] - 2s - loss: 0.0395 - mean_absolute_error: 0.1379 - val_loss: 0.1004 - val_mean_absolute_error: 0.1834\n",
      "Epoch 31/100\n",
      "110/110 [==============================] - 2s - loss: 0.0504 - mean_absolute_error: 0.1589 - val_loss: 0.1094 - val_mean_absolute_error: 0.2048\n",
      "Epoch 32/100\n",
      "110/110 [==============================] - 2s - loss: 0.0492 - mean_absolute_error: 0.1535 - val_loss: 0.1040 - val_mean_absolute_error: 0.1914\n",
      "Epoch 33/100\n",
      "110/110 [==============================] - 2s - loss: 0.0555 - mean_absolute_error: 0.1604 - val_loss: 0.1652 - val_mean_absolute_error: 0.2835\n",
      "Epoch 34/100\n",
      "110/110 [==============================] - 2s - loss: 0.0692 - mean_absolute_error: 0.1823 - val_loss: 0.1214 - val_mean_absolute_error: 0.2159\n",
      "Epoch 35/100\n",
      "110/110 [==============================] - 2s - loss: 0.0796 - mean_absolute_error: 0.1974 - val_loss: 0.1232 - val_mean_absolute_error: 0.1926\n",
      "Epoch 36/100\n",
      "110/110 [==============================] - 2s - loss: 0.0442 - mean_absolute_error: 0.1502 - val_loss: 0.1046 - val_mean_absolute_error: 0.1914\n",
      "Epoch 37/100\n",
      "110/110 [==============================] - 2s - loss: 0.0425 - mean_absolute_error: 0.1480 - val_loss: 0.1143 - val_mean_absolute_error: 0.2130\n",
      "Epoch 38/100\n",
      "110/110 [==============================] - 2s - loss: 0.0403 - mean_absolute_error: 0.1422 - val_loss: 0.1089 - val_mean_absolute_error: 0.1977\n",
      "Epoch 39/100\n",
      "110/110 [==============================] - 2s - loss: 0.0376 - mean_absolute_error: 0.1328 - val_loss: 0.1011 - val_mean_absolute_error: 0.1968\n",
      "Epoch 40/100\n",
      "110/110 [==============================] - 2s - loss: 0.0397 - mean_absolute_error: 0.1332 - val_loss: 0.0972 - val_mean_absolute_error: 0.1900\n",
      "Epoch 41/100\n",
      "110/110 [==============================] - 2s - loss: 0.0359 - mean_absolute_error: 0.1343 - val_loss: 0.1029 - val_mean_absolute_error: 0.1995\n",
      "Epoch 42/100\n",
      "110/110 [==============================] - 2s - loss: 0.0530 - mean_absolute_error: 0.1562 - val_loss: 0.0965 - val_mean_absolute_error: 0.1939\n",
      "Epoch 43/100\n",
      "110/110 [==============================] - 2s - loss: 0.0500 - mean_absolute_error: 0.1542 - val_loss: 0.1008 - val_mean_absolute_error: 0.2127\n",
      "Epoch 44/100\n",
      "110/110 [==============================] - 2s - loss: 0.0475 - mean_absolute_error: 0.1613 - val_loss: 0.1202 - val_mean_absolute_error: 0.2092\n",
      "Epoch 45/100\n",
      "110/110 [==============================] - 2s - loss: 0.0425 - mean_absolute_error: 0.1490 - val_loss: 0.1147 - val_mean_absolute_error: 0.2063\n",
      "Epoch 46/100\n",
      "110/110 [==============================] - 2s - loss: 0.0386 - mean_absolute_error: 0.1411 - val_loss: 0.1046 - val_mean_absolute_error: 0.1985\n",
      "Epoch 47/100\n",
      "110/110 [==============================] - 2s - loss: 0.0381 - mean_absolute_error: 0.1395 - val_loss: 0.0942 - val_mean_absolute_error: 0.1976\n",
      "Epoch 48/100\n",
      "110/110 [==============================] - 2s - loss: 0.0343 - mean_absolute_error: 0.1322 - val_loss: 0.0960 - val_mean_absolute_error: 0.1926\n",
      "Epoch 49/100\n",
      "110/110 [==============================] - 2s - loss: 0.0294 - mean_absolute_error: 0.1239 - val_loss: 0.0997 - val_mean_absolute_error: 0.2003\n",
      "Epoch 50/100\n",
      "110/110 [==============================] - 2s - loss: 0.0302 - mean_absolute_error: 0.1195 - val_loss: 0.0957 - val_mean_absolute_error: 0.1996\n",
      "Epoch 51/100\n",
      "110/110 [==============================] - 2s - loss: 0.0300 - mean_absolute_error: 0.1220 - val_loss: 0.0937 - val_mean_absolute_error: 0.1951\n",
      "Epoch 52/100\n",
      "110/110 [==============================] - 2s - loss: 0.0334 - mean_absolute_error: 0.1291 - val_loss: 0.1017 - val_mean_absolute_error: 0.2227\n",
      "Epoch 53/100\n",
      "110/110 [==============================] - 2s - loss: 0.0397 - mean_absolute_error: 0.1340 - val_loss: 0.1072 - val_mean_absolute_error: 0.2106\n",
      "Epoch 54/100\n",
      "110/110 [==============================] - 2s - loss: 0.0480 - mean_absolute_error: 0.1597 - val_loss: 0.1172 - val_mean_absolute_error: 0.2511\n",
      "Epoch 55/100\n",
      "110/110 [==============================] - 2s - loss: 0.0432 - mean_absolute_error: 0.1417 - val_loss: 0.1164 - val_mean_absolute_error: 0.2066\n",
      "Epoch 56/100\n",
      "110/110 [==============================] - 2s - loss: 0.0358 - mean_absolute_error: 0.1281 - val_loss: 0.1222 - val_mean_absolute_error: 0.2165\n",
      "Epoch 57/100\n",
      "110/110 [==============================] - 2s - loss: 0.0455 - mean_absolute_error: 0.1565 - val_loss: 0.0943 - val_mean_absolute_error: 0.2136\n",
      "Epoch 58/100\n",
      "110/110 [==============================] - 2s - loss: 0.0732 - mean_absolute_error: 0.1892 - val_loss: 0.1757 - val_mean_absolute_error: 0.3074\n",
      "Epoch 59/100\n",
      "110/110 [==============================] - 2s - loss: 0.0980 - mean_absolute_error: 0.1799 - val_loss: 0.3115 - val_mean_absolute_error: 0.3589\n",
      "Epoch 60/100\n",
      "110/110 [==============================] - 2s - loss: 0.2631 - mean_absolute_error: 0.2620 - val_loss: 0.0927 - val_mean_absolute_error: 0.1948\n",
      "Epoch 61/100\n",
      "110/110 [==============================] - 2s - loss: 0.1352 - mean_absolute_error: 0.2380 - val_loss: 0.1270 - val_mean_absolute_error: 0.2241\n",
      "Epoch 62/100\n",
      "110/110 [==============================] - 2s - loss: 0.0847 - mean_absolute_error: 0.1779 - val_loss: 0.1079 - val_mean_absolute_error: 0.2043\n",
      "Epoch 63/100\n",
      "110/110 [==============================] - 2s - loss: 0.0483 - mean_absolute_error: 0.1436 - val_loss: 0.1107 - val_mean_absolute_error: 0.2174\n",
      "Epoch 64/100\n",
      "110/110 [==============================] - 2s - loss: 0.0485 - mean_absolute_error: 0.1465 - val_loss: 0.1233 - val_mean_absolute_error: 0.2245\n",
      "Epoch 65/100\n",
      "110/110 [==============================] - 2s - loss: 0.0439 - mean_absolute_error: 0.1470 - val_loss: 0.1020 - val_mean_absolute_error: 0.2166\n",
      "Epoch 66/100\n",
      "110/110 [==============================] - 2s - loss: 0.0509 - mean_absolute_error: 0.1524 - val_loss: 0.1270 - val_mean_absolute_error: 0.2327\n",
      "Epoch 67/100\n",
      "110/110 [==============================] - 2s - loss: 0.0279 - mean_absolute_error: 0.1195 - val_loss: 0.0918 - val_mean_absolute_error: 0.1959\n",
      "Epoch 68/100\n",
      "110/110 [==============================] - 2s - loss: 0.0274 - mean_absolute_error: 0.1188 - val_loss: 0.0888 - val_mean_absolute_error: 0.2106\n",
      "Epoch 69/100\n",
      "110/110 [==============================] - 2s - loss: 0.0287 - mean_absolute_error: 0.1240 - val_loss: 0.0942 - val_mean_absolute_error: 0.2171\n",
      "Epoch 70/100\n",
      "110/110 [==============================] - 2s - loss: 0.0374 - mean_absolute_error: 0.1330 - val_loss: 0.0991 - val_mean_absolute_error: 0.2213\n",
      "Epoch 71/100\n",
      "110/110 [==============================] - 2s - loss: 0.0333 - mean_absolute_error: 0.1169 - val_loss: 0.1335 - val_mean_absolute_error: 0.2319\n",
      "Epoch 72/100\n",
      "110/110 [==============================] - 2s - loss: 0.0429 - mean_absolute_error: 0.1367 - val_loss: 0.1101 - val_mean_absolute_error: 0.2238\n",
      "Epoch 73/100\n",
      "110/110 [==============================] - 2s - loss: 0.0328 - mean_absolute_error: 0.1331 - val_loss: 0.1293 - val_mean_absolute_error: 0.2225\n",
      "Epoch 74/100\n",
      "110/110 [==============================] - 2s - loss: 0.0323 - mean_absolute_error: 0.1378 - val_loss: 0.1201 - val_mean_absolute_error: 0.2322\n",
      "Epoch 75/100\n",
      "110/110 [==============================] - 2s - loss: 0.0248 - mean_absolute_error: 0.1098 - val_loss: 0.1073 - val_mean_absolute_error: 0.2097\n",
      "Epoch 76/100\n",
      "110/110 [==============================] - 2s - loss: 0.0262 - mean_absolute_error: 0.1160 - val_loss: 0.0980 - val_mean_absolute_error: 0.2164\n",
      "Epoch 77/100\n",
      "110/110 [==============================] - 2s - loss: 0.0276 - mean_absolute_error: 0.1176 - val_loss: 0.0997 - val_mean_absolute_error: 0.2120\n",
      "Epoch 78/100\n",
      "110/110 [==============================] - 2s - loss: 0.0220 - mean_absolute_error: 0.1039 - val_loss: 0.0969 - val_mean_absolute_error: 0.2253\n",
      "Epoch 79/100\n",
      "110/110 [==============================] - 2s - loss: 0.0207 - mean_absolute_error: 0.1021 - val_loss: 0.1105 - val_mean_absolute_error: 0.2304\n",
      "Epoch 80/100\n",
      "110/110 [==============================] - 2s - loss: 0.0173 - mean_absolute_error: 0.0925 - val_loss: 0.1113 - val_mean_absolute_error: 0.2200\n",
      "Epoch 81/100\n",
      "110/110 [==============================] - 2s - loss: 0.0183 - mean_absolute_error: 0.0957 - val_loss: 0.1044 - val_mean_absolute_error: 0.2284\n",
      "Epoch 82/100\n",
      "110/110 [==============================] - 2s - loss: 0.0251 - mean_absolute_error: 0.1056 - val_loss: 0.1423 - val_mean_absolute_error: 0.2287\n",
      "Epoch 83/100\n",
      "110/110 [==============================] - 2s - loss: 0.0533 - mean_absolute_error: 0.1534 - val_loss: 0.1235 - val_mean_absolute_error: 0.2444\n",
      "Epoch 84/100\n",
      "110/110 [==============================] - 2s - loss: 0.0592 - mean_absolute_error: 0.1528 - val_loss: 0.1101 - val_mean_absolute_error: 0.2475\n",
      "Epoch 85/100\n",
      "110/110 [==============================] - 2s - loss: 0.0630 - mean_absolute_error: 0.1561 - val_loss: 0.1020 - val_mean_absolute_error: 0.2293\n",
      "Epoch 86/100\n",
      "110/110 [==============================] - 2s - loss: 0.0559 - mean_absolute_error: 0.1468 - val_loss: 0.1077 - val_mean_absolute_error: 0.2446\n",
      "Epoch 87/100\n",
      "110/110 [==============================] - 2s - loss: 0.0300 - mean_absolute_error: 0.1166 - val_loss: 0.1075 - val_mean_absolute_error: 0.2268\n",
      "Epoch 88/100\n",
      "110/110 [==============================] - 2s - loss: 0.0320 - mean_absolute_error: 0.1232 - val_loss: 0.1187 - val_mean_absolute_error: 0.2185\n",
      "Epoch 89/100\n",
      "110/110 [==============================] - 2s - loss: 0.0232 - mean_absolute_error: 0.1089 - val_loss: 0.1338 - val_mean_absolute_error: 0.2352\n",
      "Epoch 90/100\n",
      "110/110 [==============================] - 2s - loss: 0.0189 - mean_absolute_error: 0.1020 - val_loss: 0.1218 - val_mean_absolute_error: 0.2434\n",
      "Epoch 91/100\n",
      "110/110 [==============================] - 2s - loss: 0.0195 - mean_absolute_error: 0.1013 - val_loss: 0.1288 - val_mean_absolute_error: 0.2405\n",
      "Epoch 92/100\n",
      "110/110 [==============================] - 2s - loss: 0.0155 - mean_absolute_error: 0.0931 - val_loss: 0.1202 - val_mean_absolute_error: 0.2402\n",
      "Epoch 93/100\n",
      "110/110 [==============================] - 2s - loss: 0.0137 - mean_absolute_error: 0.0841 - val_loss: 0.1304 - val_mean_absolute_error: 0.2493\n",
      "Epoch 94/100\n",
      "110/110 [==============================] - 2s - loss: 0.0143 - mean_absolute_error: 0.0909 - val_loss: 0.1425 - val_mean_absolute_error: 0.2411\n",
      "Epoch 95/100\n",
      "110/110 [==============================] - 2s - loss: 0.0133 - mean_absolute_error: 0.0825 - val_loss: 0.1504 - val_mean_absolute_error: 0.2499\n",
      "Epoch 96/100\n",
      "110/110 [==============================] - 2s - loss: 0.0129 - mean_absolute_error: 0.0844 - val_loss: 0.1315 - val_mean_absolute_error: 0.2427\n",
      "Epoch 97/100\n",
      "110/110 [==============================] - 2s - loss: 0.0139 - mean_absolute_error: 0.0854 - val_loss: 0.1643 - val_mean_absolute_error: 0.2660\n",
      "Epoch 98/100\n",
      "110/110 [==============================] - 2s - loss: 0.0125 - mean_absolute_error: 0.0811 - val_loss: 0.1468 - val_mean_absolute_error: 0.2499\n",
      "Epoch 99/100\n",
      "110/110 [==============================] - 2s - loss: 0.0129 - mean_absolute_error: 0.0855 - val_loss: 0.1554 - val_mean_absolute_error: 0.2793\n",
      "Epoch 100/100\n",
      "110/110 [==============================] - 2s - loss: 0.0152 - mean_absolute_error: 0.0918 - val_loss: 0.1762 - val_mean_absolute_error: 0.2398\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train[:,:,-1], batch_size=2, epochs=100, validation_data=(x_test,y_test[:,:,-1]), callbacks=[tensorboard_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
